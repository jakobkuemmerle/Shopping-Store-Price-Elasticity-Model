{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f48b7a41",
   "metadata": {},
   "source": [
    "### Functions for cleaning + Feature selection + Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b6a3258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def load_transaction_data(trans_file_path):\n",
    "    trans = pd.read_csv(trans_file_path, names=['sku', 'storeid', 'register', 'trannum', 'interID', 'saledate', 'stype', 'quantity',\n",
    "                                                'orgprice', 'amt', 'seq', 'mic', 'unknown'])\n",
    "    \n",
    "    # Keep only purchases and positive amounts\n",
    "    trans = trans[(trans['stype'] == 'P') & (trans['amt'] > 1) & (trans['orgprice'] > 1)]\n",
    "    \n",
    "    # Drop irrelevant columns\n",
    "    trans = trans.drop(columns=['interID', 'stype', 'mic', 'unknown'])\n",
    "    \n",
    "    return trans\n",
    "\n",
    "def load_sku_data(skst_file_path):\n",
    "    skst = pd.read_csv(skst_file_path, names=['sku', 'storeid', 'cost', 'retail', 'unknown'])\n",
    "    \n",
    "    # Drop irrelevant columns\n",
    "    skst = skst.drop(columns=['unknown'])\n",
    "    \n",
    "    # Get non-zero mean retail for each SKU\n",
    "    mean_retail = skst.groupby('sku')['retail'].mean().replace(0, np.nan).fillna(0)\n",
    "    \n",
    "    return skst, mean_retail\n",
    "\n",
    "def merge_dataframes(trans, skst, mean_retail):\n",
    "    trans = pd.merge(trans, skst, on=['sku', 'storeid'], how='left')\n",
    "    \n",
    "    # Fill NaN values in 'retail' and 'orgprice' with appropriate values\n",
    "    trans['retail'] = trans['retail'].fillna(trans['sku'].map(mean_retail)).fillna(trans['orgprice'])\n",
    "    trans['orgprice'] = trans['orgprice'].fillna(trans['sku'].map(mean_retail))\n",
    "    \n",
    "    return trans\n",
    "\n",
    "def feature_engineering(trans):\n",
    "    trans['saledate'] = pd.to_datetime(trans['saledate'])\n",
    "    trans['day_of_week'] = trans['saledate'].dt.dayofweek\n",
    "    trans['month'] = trans['saledate'].dt.month\n",
    "    trans['weekend'] = trans['day_of_week'].apply(lambda x: 1 if x >= 4 else 0)\n",
    "    \n",
    "    trans['amt'] = np.where(trans['amt'] == 0, trans['retail'], trans['amt'])\n",
    "    trans['amt'] = np.where(trans['amt'] == 0, trans['orgprice'], trans['amt'])\n",
    "    \n",
    "    trans['percent_discount'] = np.maximum(0, (trans['orgprice'] - trans['amt']) / trans['orgprice'])\n",
    "    trans.loc[trans['amt'] >= trans['orgprice'], 'percent_discount'] = 0\n",
    "    trans.loc[trans['orgprice'] <= 0, 'percent_discount'] = 0\n",
    "    trans.loc[trans['percent_discount'] < 0, 'percent_discount'] = 0\n",
    "    \n",
    "    trans['final_sale'] = np.where(trans['percent_discount'] > 0.5, 1, 0)\n",
    "    \n",
    "    return trans\n",
    "\n",
    "def join_dataframes(input_df, csv_file_path, columns, join_key='sku', how='inner'):\n",
    "    columns += [join_key]\n",
    "    csv_df = pd.read_csv(csv_file_path)\n",
    "    csv_df.columns = ['sku', 'deptid', 'classid', 'upc', 'style', 'color', 'size', 'packsize', 'vendor', 'brand']\n",
    "    \n",
    "    joined_df = pd.merge(input_df, csv_df[columns], on=join_key, how=how)\n",
    "    \n",
    "    return joined_df\n",
    "\n",
    "def get_high_value_df(joined_df, n=50):\n",
    "    sku_sum_revenue = joined_df.groupby('sku')['amt'].sum()\n",
    "    sorted_skus = sku_sum_revenue.sort_values(ascending=False).reset_index()\n",
    "    sorted_skus['cumulative_sum'] = sorted_skus['amt'].cumsum()\n",
    "    \n",
    "    max_revenue = sorted_skus['cumulative_sum'].max() / (100 / n)\n",
    "    high_value_skus = sorted_skus[sorted_skus.cumulative_sum < max_revenue]\n",
    "    high_value_df = joined_df[joined_df['sku'].isin(high_value_skus['sku'])]\n",
    "    \n",
    "    return high_value_df\n",
    "\n",
    "def filter_min_average_discount(high_value_df, percentage_column='percent_discount', min_average_discount=0.03):\n",
    "    average_discount = high_value_df.groupby('sku')[percentage_column].mean().reset_index(name='avg_discount')\n",
    "    filtered_df = average_discount[average_discount['avg_discount'] >= min_average_discount]\n",
    "    merged_df = pd.merge(high_value_df, filtered_df, on='sku', how='inner')\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4650a360",
   "metadata": {},
   "source": [
    "### Pipeline to execute all Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9becc872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(trans_file_path, skst_file_path, clean_sku_file_path):\n",
    "    trans = load_transaction_data(trans_file_path)\n",
    "    skst, mean_retail = load_sku_data(skst_file_path)\n",
    "    trans = merge_dataframes(trans, skst, mean_retail)\n",
    "    trans = feature_engineering(trans)\n",
    "    \n",
    "    columns = ['brand', 'classid']\n",
    "    joined_df = join_dataframes(trans, clean_sku_file_path, columns)\n",
    "    \n",
    "    high_value_df = get_high_value_df(joined_df)\n",
    "    \n",
    "    filtered_df = filter_min_average_discount(high_value_df)\n",
    "    \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b39ca11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_basket_data(filtered_df, num_baskets, filter_single_baskets = False):\n",
    "\n",
    "    baskets = filtered_df.copy()\n",
    "    baskets['sku'] = baskets['sku'].astype(str)\n",
    "    \n",
    "    baskets = baskets.groupby(['saledate', 'storeid', 'register', 'trannum'])['sku'].agg(['count', 'nunique', list]).reset_index()\n",
    "    baskets.columns = ['saledate', 'storeid', 'register', 'trannum', 'TotalItems', 'UniqueItems', 'Items']\n",
    "    \n",
    "    total_num_baskets = len(baskets)\n",
    "    \n",
    "    if(filter_single_baskets):\n",
    "        baskets = baskets[(baskets['Items'].apply(len) > 1) & (baskets['UniqueItems'] > 1)]\n",
    "    \n",
    "    filtered_num_baskets = len(baskets)\n",
    "    baskets = baskets.sample(frac=1).head(num_baskets)\n",
    "    \n",
    "    return baskets, total_num_baskets, filtered_num_baskets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5659ef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def preprocess_basket_data(baskets_df, *groupby_columns):\n",
    "    \"\"\"\n",
    "    Preprocesses basket data by converting it to a binary representation.\n",
    "    Returns:\n",
    "    - basket_encoded: DataFrame, the preprocessed binary representation\n",
    "    \"\"\"\n",
    "    basket_encoded = (\n",
    "        baskets_df.set_index(list(groupby_columns))['Items']\n",
    "        .apply(lambda x: list(set(x)))\n",
    "        .apply(pd.Series)\n",
    "        .stack()\n",
    "        .reset_index()\n",
    "        .groupby(list(groupby_columns) + [0])\n",
    "        .size()\n",
    "        .unstack()\n",
    "        .reset_index()\n",
    "        .fillna(0)\n",
    "        .set_index(list(groupby_columns))\n",
    "    )\n",
    "    return basket_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "549ad14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "def run_apriori(data, min_support, min_confidence):\n",
    "    \"\"\"\n",
    "    Run the Apriori algorithm on the provided DataFrame and return relevant results.\n",
    "    \"\"\"\n",
    "    # Convert the binary representation to boolean for Apriori algorithm\n",
    "    basket_sets = data.astype(bool)\n",
    "\n",
    "    # Use Apriori algorithm to find frequent itemsets\n",
    "    frequent_itemsets = apriori(basket_sets, min_support=min_support, use_colnames=True)\n",
    "\n",
    "    # Generate association rules\n",
    "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
    "\n",
    "    return frequent_itemsets, rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5e69d4",
   "metadata": {},
   "source": [
    "# Execute Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfea5c1",
   "metadata": {},
   "source": [
    "### Option 1: Execute all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdfe203e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trans_final shape: (23900020, 19)\n",
      "Amount in Transaction Selection: 699341754.8000008\n",
      "total num of baskets: 15128823\n",
      "filtered num of baskets: 3520231\n",
      "final selection of baskets: (100000, 7)\n",
      "executed! Let's Go!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 01. Read Data and Filter trans Data\n",
    "directory = 'Dillards POS/'\n",
    "skst_file_path = directory + 'skstinfo.csv'\n",
    "trans_file_path = directory + 'trans_final.csv'\n",
    "clean_sku_file_path = directory + 'sku_final.csv'\n",
    "# 02. process_data\n",
    "trans_final = process_data(trans_file_path, skst_file_path, clean_sku_file_path)\n",
    "print(f'trans_final shape: {trans_final.shape}')\n",
    "print(f'Amount in Transaction Selection: {trans_final[\"amt\"].sum()}')\n",
    "\n",
    "# 03. Process_basket_data\n",
    "filter_single_baskets = True\n",
    "num_baskets = 100000\n",
    "baskets_final,total_num_baskets, filtered_num_baskets = process_basket_data(trans_final, num_baskets, filter_single_baskets)\n",
    "\n",
    "print(f'total num of baskets: {total_num_baskets}')\n",
    "print(f'filtered num of baskets: {filtered_num_baskets}')\n",
    "print(f'final selection of baskets: {baskets_final.shape}')\n",
    "\n",
    "# 04. Preprocess_basket_data\n",
    "groupby_columns = ['saledate', 'storeid', 'register', 'trannum']\n",
    "basket_encoded = preprocess_basket_data(baskets_final, *groupby_columns)\n",
    "\n",
    "# 05. Run_apriori\n",
    "min_support_threshold = 0.001\n",
    "min_confidence_threshold = 0.5\n",
    "frequent_itemsets, rules = run_apriori(basket_encoded, min_support_threshold, min_confidence_threshold)\n",
    "\n",
    "print(\"executed! Let's Go!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3e059d",
   "metadata": {},
   "source": [
    "### Option 2: Execute only Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798045c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03. Process_basket_data\n",
    "filter_single_baskets = True\n",
    "num_baskets = 200000\n",
    "baskets_final,total_num_baskets, filtered_num_baskets = process_basket_data(trans_final, num_baskets, filter_single_baskets)\n",
    "\n",
    "print(f'total num of baskets: {total_num_baskets}')\n",
    "print(f'filtered num of baskets: {filtered_num_baskets}')\n",
    "print(f'final selection of baskets: {baskets_final.shape}')\n",
    "\n",
    "# 04. Preprocess_basket_data\n",
    "groupby_columns = ['saledate', 'storeid', 'register', 'trannum']\n",
    "basket_encoded = preprocess_basket_data(baskets_final, *groupby_columns)\n",
    "\n",
    "# 05. Run_apriori\n",
    "min_support_threshold = 0.001\n",
    "min_confidence_threshold = 0.5\n",
    "frequent_itemsets, rules = run_apriori(basket_encoded, min_support_threshold, min_confidence_threshold)\n",
    "\n",
    "print(\"executed! Let's Go!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dbca1b",
   "metadata": {},
   "source": [
    "### Explore Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "001160f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>zhangs_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(6062521, 6032521)</td>\n",
       "      <td>(6072521)</td>\n",
       "      <td>0.00123</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.00107</td>\n",
       "      <td>0.869919</td>\n",
       "      <td>414.247000</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>7.671356</td>\n",
       "      <td>0.998815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(6062521)</td>\n",
       "      <td>(6072521)</td>\n",
       "      <td>0.00182</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.00147</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>384.615385</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>5.189080</td>\n",
       "      <td>0.999219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(6032521)</td>\n",
       "      <td>(6072521)</td>\n",
       "      <td>0.00181</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.00142</td>\n",
       "      <td>0.784530</td>\n",
       "      <td>373.585898</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>4.631279</td>\n",
       "      <td>0.999132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(6480353)</td>\n",
       "      <td>(6470353)</td>\n",
       "      <td>0.00149</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.00116</td>\n",
       "      <td>0.778523</td>\n",
       "      <td>389.261745</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>4.506121</td>\n",
       "      <td>0.998919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(6490353)</td>\n",
       "      <td>(6470353)</td>\n",
       "      <td>0.00182</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.00140</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>384.615385</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>4.324667</td>\n",
       "      <td>0.999219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           antecedents consequents  antecedent support  consequent support  \\\n",
       "25  (6062521, 6032521)   (6072521)             0.00123              0.0021   \n",
       "7            (6062521)   (6072521)             0.00182              0.0021   \n",
       "5            (6032521)   (6072521)             0.00181              0.0021   \n",
       "10           (6480353)   (6470353)             0.00149              0.0020   \n",
       "12           (6490353)   (6470353)             0.00182              0.0020   \n",
       "\n",
       "    support  confidence        lift  leverage  conviction  zhangs_metric  \n",
       "25  0.00107    0.869919  414.247000  0.001067    7.671356       0.998815  \n",
       "7   0.00147    0.807692  384.615385  0.001466    5.189080       0.999219  \n",
       "5   0.00142    0.784530  373.585898  0.001416    4.631279       0.999132  \n",
       "10  0.00116    0.778523  389.261745  0.001157    4.506121       0.998919  \n",
       "12  0.00140    0.769231  384.615385  0.001396    4.324667       0.999219  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules.sort_values('confidence', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efefd3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>zhangs_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(7596135)</td>\n",
       "      <td>(6656135)</td>\n",
       "      <td>0.00447</td>\n",
       "      <td>0.00746</td>\n",
       "      <td>0.00250</td>\n",
       "      <td>0.559284</td>\n",
       "      <td>74.971061</td>\n",
       "      <td>0.002467</td>\n",
       "      <td>2.252109</td>\n",
       "      <td>0.991092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(6072521)</td>\n",
       "      <td>(6062521)</td>\n",
       "      <td>0.00210</td>\n",
       "      <td>0.00182</td>\n",
       "      <td>0.00147</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>384.615385</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>3.327267</td>\n",
       "      <td>0.999499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(6062521)</td>\n",
       "      <td>(6072521)</td>\n",
       "      <td>0.00182</td>\n",
       "      <td>0.00210</td>\n",
       "      <td>0.00147</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>384.615385</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>5.189080</td>\n",
       "      <td>0.999219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(6072521)</td>\n",
       "      <td>(6032521)</td>\n",
       "      <td>0.00210</td>\n",
       "      <td>0.00181</td>\n",
       "      <td>0.00142</td>\n",
       "      <td>0.676190</td>\n",
       "      <td>373.585898</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>3.082646</td>\n",
       "      <td>0.999422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(6032521)</td>\n",
       "      <td>(6072521)</td>\n",
       "      <td>0.00181</td>\n",
       "      <td>0.00210</td>\n",
       "      <td>0.00142</td>\n",
       "      <td>0.784530</td>\n",
       "      <td>373.585898</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>4.631279</td>\n",
       "      <td>0.999132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   antecedents consequents  antecedent support  consequent support  support  \\\n",
       "20   (7596135)   (6656135)             0.00447             0.00746  0.00250   \n",
       "6    (6072521)   (6062521)             0.00210             0.00182  0.00147   \n",
       "7    (6062521)   (6072521)             0.00182             0.00210  0.00147   \n",
       "4    (6072521)   (6032521)             0.00210             0.00181  0.00142   \n",
       "5    (6032521)   (6072521)             0.00181             0.00210  0.00142   \n",
       "\n",
       "    confidence        lift  leverage  conviction  zhangs_metric  \n",
       "20    0.559284   74.971061  0.002467    2.252109       0.991092  \n",
       "6     0.700000  384.615385  0.001466    3.327267       0.999499  \n",
       "7     0.807692  384.615385  0.001466    5.189080       0.999219  \n",
       "4     0.676190  373.585898  0.001416    3.082646       0.999422  \n",
       "5     0.784530  373.585898  0.001416    4.631279       0.999132  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules.sort_values('support', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03c66689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e7310b",
   "metadata": {},
   "source": [
    "### Check if Rules seem plausible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8aea0f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.00111</td>\n",
       "      <td>(6696135, 6656135)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0.00117</td>\n",
       "      <td>(6706135, 6656135)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0.00250</td>\n",
       "      <td>(7596135, 6656135)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.00111</td>\n",
       "      <td>(6752521, 6742521)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.00107</td>\n",
       "      <td>(6072521, 6062521, 6032521)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     support                     itemsets\n",
       "209  0.00111           (6696135, 6656135)\n",
       "210  0.00117           (6706135, 6656135)\n",
       "211  0.00250           (7596135, 6656135)\n",
       "212  0.00111           (6752521, 6742521)\n",
       "213  0.00107  (6072521, 6062521, 6032521)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_itemsets.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71c7ebe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "saledate    storeid  register  trannum\n",
       "2004-08-01  4907     70        700        1.0\n",
       "2004-08-02  402      30        1400       0.0\n",
       "2004-08-09  9603     590       2000       1.0\n",
       "2004-08-13  3007     750       300        1.0\n",
       "2004-08-18  5903     50        2500       1.0\n",
       "Name: 6460353, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basket_encoded[basket_encoded['6440353'] == 1]['6460353'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44c974e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count for SKU 6276633: 1743\n",
      "Count for SKU 6756633: 1686\n",
      "Count for both SKUs: 981\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sku_1 = 6276633\n",
    "sku_2 = 6756633\n",
    "\n",
    "# Create a column indicating whether each row contains the specified SKUs\n",
    "trans_final['has_sku_1'] = (trans_final['sku'] == sku_1)\n",
    "trans_final['has_sku_2'] = (trans_final['sku'] == sku_2)\n",
    "\n",
    "# Group by basket identifiers and count occurrences\n",
    "counts = trans_final.groupby(['saledate', 'storeid', 'register', 'trannum'])[['has_sku_1', 'has_sku_2']].any().reset_index()\n",
    "\n",
    "# Count occurrences of each SKU and both SKUs across all baskets\n",
    "sku_1_count = counts['has_sku_1'].sum()\n",
    "sku_2_count = counts['has_sku_2'].sum()\n",
    "both_skus_count = (counts['has_sku_1'] & counts['has_sku_2']).sum()\n",
    "\n",
    "# Print the counts\n",
    "print(f\"Count for SKU {sku_1}: {sku_1_count}\")\n",
    "print(f\"Count for SKU {sku_2}: {sku_2_count}\")\n",
    "print(f\"Count for both SKUs: {both_skus_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74fb347",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
